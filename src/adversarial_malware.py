import torch
import torch.nn.functional as F
import numpy as np
from src.utils import load_config, log

def generate_adversarial_example(model, original_bytes, target_class=0):
    """
    Generates an adversarial malware example based on the provided pseudocode algorithm.
    
    Algorithm:
    1. Append q padding bytes (randomly initialized).
    2. Iteratively update padding bytes to minimize the loss (move towards benign class).
    3. Update rule uses gradient of the embedding vector.

    Args:
        model: The PyTorch model (MalConvGCT). embedding layer should be accessible via model.embd.
        original_bytes (bytes or List[int] or np.array): The original malware byte sequence.
        target_class (int): The target class index (0 for benign).
        
    Returns:
        np.array: The adversarial example byte sequence.
    """
    # Load Configuration
    config = load_config()
    attack_config = config.get('attack', {})
    
    # Hyperparameters from config
    padding_ratio = attack_config.get('padding_ratio', 0.01) # Default 1%
    T = attack_config.get('iterations', 10) # Max iterations
    
    # 1. Setup Input (x)
    # Ensure original_bytes is a numpy array (integers)
    if isinstance(original_bytes, (bytes, bytearray)):
        x_k = np.frombuffer(original_bytes, dtype=np.uint8).astype(np.int64)
    elif isinstance(original_bytes, list):
        x_k = np.array(original_bytes, dtype=np.int64)
    else:
        x_k = np.array(original_bytes, dtype=np.int64)
        
    k = len(x_k)
    q = int(k * padding_ratio) # Calculate number of padding bytes
    if q == 0:
        q = 1 # Minimum 1 byte padding
        
    log(f"Adversarial Attack Start: Original Size={k}, Padding Size(q)={q}, Iterations(T)={T}", "INFO")

    # 2. Randomly set the first q padding bytes
    # Initialize padding with random bytes (0-255)
    padding = np.random.randint(0, 256, size=q, dtype=np.int64)
    x_prime = np.concatenate([x_k, padding]) # Combined input of size k + q
    
    # Device setup
    device = next(model.parameters()).device
    model.eval() # Gradient is needed, but we keep eval mode for batch norm etc.
    
    # Prepare Embedding Matrix (lookup table)
    embedding_weight = model.embd.weight.detach() # (257, D)
    byte_embeddings = embedding_weight[1:257] # (256, D)
    
    # Model parameters for index calculation
    window_size = getattr(model, 'window_size', 256)
    stride = getattr(model, 'stride', 64)
    
    for t in range(T):
        # 5. Check stopping condition
        # First, run normal forward pass to check probability and Update 'saved_indices' (natural winners)
        model.eval()
        
        # Ensure _is_explaining is False initially to let model calculate natural winners
        if hasattr(model, "_is_explaining"):
             model._is_explaining = False
             
        tensor_input_check = torch.from_numpy(x_prime).unsqueeze(0).to(device) # (1, L)
        
        # This forward pass updates model.saved_indices with the current max-pooling winners
        with torch.no_grad():
             check_outputs = model(tensor_input_check + 1)
             
        check_logits = check_outputs[0] if isinstance(check_outputs, tuple) else check_outputs
        probs = F.softmax(check_logits, dim=1)
        prob_malware = probs[0, 1]
        
        if prob_malware.item() < 0.5:
            log(f"Success at iteration {t}: Malware Prob = {prob_malware.item():.4f}", "INFO")
            return x_prime.astype(np.uint8)
            
        # 6. Compute Gradient w_j for padding bytes
        # To avoid vanishing gradients due to MaxPooling ignoring padding,
        # we FORCE the model to look at padding regions by injecting them into 'saved_indices'.
        
        # Calculate indices covering the padding region
        # Padding is from k to k+q
        # Windows start at intervals of 'stride'.
        # We want all windows that overlap with padding.
        # Window i starts at i*stride. Ends at i*stride + window_size.
        # We want i*stride + window_size > k
        
        start_win_idx = max(0, (k - window_size) // stride)
        end_win_idx = (len(x_prime) - window_size) // stride
        
        padding_window_indices = np.arange(start_win_idx, end_win_idx + 1) * stride
        
        # Inject into saved_indices
        if hasattr(model, "saved_indices"):
            current_winners = model.saved_indices[0] # Batch 0
            # Combine natural winners with forced padding windows
            augmented_winners = np.unique(np.concatenate([current_winners, padding_window_indices])).astype(np.int64)
            model.saved_indices = [augmented_winners]
            
        # Now run forward pass with Embeddings and _is_explaining=True 
        # This forces seq2fix to use our augmented saved_indices
        
        input_indices = tensor_input_check + 1
        embedded_input = model.embd(input_indices).detach()
        embedded_input.requires_grad = True
        
        # Temporarily set _is_explaining to True to bypass re-calculation of indices
        original_is_explaining = getattr(model, "_is_explaining", False)
        model._is_explaining = True
        
        try:
            outputs = model(embedded_input)
            logits = outputs[0] if isinstance(outputs, tuple) else outputs
            
            # Loss: Minimize Malware Prob
            loss_prob = F.softmax(logits, dim=1)[0, 1]
            
            model.zero_grad()
            loss_prob.backward()
            
            # Gradient w.r.t embeddings
            grad = embedded_input.grad # (1, L, D)
            
        finally:
            model._is_explaining = original_is_explaining

        # If grad is None (should not happen with this fix), skip
        if grad is None:
             continue
             
        # We only care about the padding bytes.
        # Padding starts at index `k`.
        padding_grads = grad[0, k:, :] # (q, D)
        
        # Iterate over each padding byte to update (Process 6~15)
        # We can implement this vectorized for all padding bytes `p`.
        
        # Current embeddings of padding bytes
        # x_j is the current embedding vector z_j in paper notation? 
        # Paper: m_i is embedding of byte i. z_j is current embedding.
        # s_i = n_j dot (m_i - z_j)
        # d_i = || m_i - (z_j + s_i * n_j) ||^2
        
        # Note: In the paper (gradient-based attack), they project the desired change onto the embedding manifold.
        # w_j = - grad (negative gradient)
        
        # Vectorized Update:
        # padding_grads: (q, D) -> w_j
        
        w = -padding_grads # Negative gradient direction
        
        # Normalize w -> n
        w_norm = torch.norm(w, p=2, dim=1, keepdim=True) + 1e-8
        n = w / w_norm # (q, D)
        
        # Current embedding z_j
        z = embedded_input[0, k:, :].detach() # (q, D)
        
        # We need to find `best_i` for each position `p`.
        # Compute scores for all 256 candidate bytes.
        
        # M: All byte embeddings (256, D)
        M = byte_embeddings # (256, D)
        
        # Expand for broadcasting
        # We want to compute for each padding pos `j` (q total) and each candidate `i` (256 total).
        
        # n: (q, D) -> (q, 1, D)
        n_expanded = n.unsqueeze(1) 
        
        # z: (q, D) -> (q, 1, D)
        z_expanded = z.unsqueeze(1)
        
        # M: (256, D) -> (1, 256, D)
        M_expanded = M.unsqueeze(0)
        
        # diff: m_i - z_j (q, 256, D)
        diff = M_expanded - z_expanded
        
        # s_i = n_j dot (m_i - z_j)
        # dot product over dim 2
        s = torch.sum(n_expanded * diff, dim=2) # (q, 256)
        
        # s_i > 0 condition mask
        valid_mask = s > 0 # (q, 256)
        
        # Project diff onto n: (z_j + s_i * n_j) - z_j = s_i * n_j
        # Distance d_i = || m_i - (z_j + s_i * n_j) ||
        #              = || (m_i - z_j) - (s_i * n_j) ||
        #              = || diff - s * n ||
        
        # s * n: (q, 256, 1) * (q, 1, D) -> (q, 256, D)
        proj = s.unsqueeze(2) * n_expanded
        
        # residual
        residual = diff - proj # (q, 256, D)
        
        # d_i squared norm
        d = torch.norm(residual, p=2, dim=2) # (q, 256)
        
        # Select argmin d_i where s_i > 0
        # If no s_i > 0, we might want to stay put or pick random?
        # Paper implies we move in direction of gradient.
        # Set d to infinity where s <= 0
        
        d_masked = d.clone()
        d_masked[~valid_mask] = float('inf')
        
        # Find min index
        min_vals, best_indices = torch.min(d_masked, dim=1) # (q,)
        
        # Update x_prime padding part
        # best_indices contains values 0..255 (corresponding to byte values)
        # Check if valid (min_val is not inf)
        
        final_padding_bytes = x_prime[k:].copy()
        
        cpu_best_indices = best_indices.cpu().numpy()
        cpu_min_vals = min_vals.cpu().detach().numpy()
        
        for idx in range(q):
            if cpu_min_vals[idx] != float('inf'):
                final_padding_bytes[idx] = cpu_best_indices[idx]
                
        x_prime[k:] = final_padding_bytes
        
        if (t + 1) % 5 == 0:
             log(f"Iteration {t+1}/{T}: Malware Prob = {prob_malware.item():.4f}", "INFO")

    log(f"Attack Failed to cross threshold after {T} iterations. Final Prob: {prob_malware.item():.4f}", "WARNING")
    return x_prime.astype(np.uint8)
